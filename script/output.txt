<table>
    <tr>
        <td><a href="https://www.computer.org/csdl/proceedings-article/sp/2024/313000a120/1Ub23teQ7PG">Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack</a></td>
        <td>2024</td>
        <td>SP</td>
        <td>Feature-based</td>
        <td>Membership Inference</td>
        <td>Differential Privacy, Privacy-Preserving Models, DP-SGD</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://proceedings.mlr.press/v206/pawelczyk23a.html">On the Privacy Risks of Algorithmic Recourse</a></td>
        <td>2023</td>
        <td>AISTATS</td>
        <td>Counterfactual</td>
        <td>Membership Inference</td>
        <td>Differential Privacy</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/full/10.1145/3608482">The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks</a></td>
        <td>2023</td>
        <td>TIST</td>
        <td>Counterfactual</td>
        <td>Linkage</td>
        <td>Anonymisaion</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/abs/10.1145/3580305.3599343">Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations</a></td>
        <td>2023</td>
        <td>KDD</td>
        <td>Counterfactual</td>
        <td class='code'>-</td>
        <td>Perturbation</td>
        <td><a href="https://github.com/isVy08/L2C/">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://petsymposium.org/popets/2023/popets-2023-0041.pdf">Private Graph Extraction via Feature Explanations</a></td>
        <td>2023</td>
        <td>PETS</td>
        <td>Feature-based</td>
        <td>Graph Extraction</td>
        <td>Perturbation</td>
        <td><a href="https://github.com/iyempissy/graph-stealing-attacks-with-explanation">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2311.14137">Privacy-Preserving Algorithmic Recourse</a></td>
        <td>2023</td>
        <td>ICAIF</td>
        <td>Counterfactual</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2308.04341">Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage</a></td>
        <td>2023</td>
        <td>ICML-Workshop</td>
        <td>Counterfactual</td>
        <td>Membership Inference</td>
        <td>Differential Privacy</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2308.15099">Probabilistic Dataset Reconstruction from Interpretable Models</a></td>
        <td>2023</td>
        <td>arXiv</td>
        <td>Interpretable Surrogates</td>
        <td>Data Reconstruction</td>
        <td class='code'>-</td>
        <td><a href="https://github.com/ferryjul/ProbabilisticDatasetsReconstruction">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1495">DeepFixCX: Explainable privacy-preserving image compression for medical image analysis</a></td>
        <td>2023</td>
        <td>WIREs-DMKD</td>
        <td>Case-based</td>
        <td>Identity recognition</td>
        <td>Anonymisation</td>
        <td><a href="https://github.com/adgaudio/DeepFixCX">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://eprint.iacr.org/2023/1859">XorSHAP: Privacy-Preserving Explainable AI for Decision Tree Models</a></td>
        <td>2023</td>
        <td>Preprint</td>
        <td>Shapley</td>
        <td class='code'>-</td>
        <td>Multi-party Computation</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td class='code'>-</td>
        <td>2023</td>
        <td>Github</td>
        <td>ALE plot</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td><a href="https://github.com/lange-martin/dp-global-xai">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557362">Inferring Sensitive Attributes from Model Explanations</a></td>
        <td>2022</td>
        <td>CIKM</td>
        <td>Gradient-based, Perturbation-based</td>
        <td>Attribute Inference</td>
        <td class='code'>-</td>
        <td><a href="https://github.com/vasishtduddu/AttInfExplanations">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/abs/10.1145/3531146.3533235">Model explanations with differential privacy</a></td>
        <td>2022</td>
        <td>FAccT</td>
        <td>Feature-based</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/10.1145/3531146.3533188">DualCF: Efficient Model Extraction Attack from Counterfactual Explanations</a></td>
        <td>2022</td>
        <td>FAccT</td>
        <td>Counterfactual</td>
        <td>Model Extraction</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/abs/10.1145/3548606.3560573">Feature Inference Attack on Shapley Values</a></td>
        <td>2022</td>
        <td>CCS</td>
        <td>Shapley</td>
        <td>Attribute/Feature Inference</td>
        <td>Low-dimensional</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://ieeexplore.ieee.org/abstract/document/10063510/">Evaluating the privacy exposure of interpretable global explainers</a></td>
        <td>2022</td>
        <td>CogMI</td>
        <td>Interpretable Surrogates</td>
        <td>Membership Inference</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://ieeexplore.ieee.org/document/9729808/">Privacy-Preserving Case-Based Explanations: Enabling Visual Interpretability by Protecting Privacy</a></td>
        <td>2022</td>
        <td>IEEE Access</td>
        <td>Example-based</td>
        <td class='code'>-</td>
        <td>Anonymisation</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2206.14004">On the amplification of security and privacy risks by post-hoc explanations in machine learning models</a></td>
        <td>2022</td>
        <td>arXiv</td>
        <td>Feature-based</td>
        <td>Membership Inference</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2208.02878">Differentially Private Counterfactuals via Functional Mechanism</a></td>
        <td>2022</td>
        <td>arXiv</td>
        <td>Counterfactual</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2206.00511">Differentially Private Shapley Values for Data Evaluation</a></td>
        <td>2022</td>
        <td>arXiv</td>
        <td>Shapley</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td><a href="https://github.com/amiratag/DataShapley">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Exploiting_Explanations_for_Model_Inversion_Attacks_ICCV_2021_paper.html">Exploiting Explanations for Model Inversion Attacks</a></td>
        <td>2021</td>
        <td>ICCV</td>
        <td>Gradient-based, Interpretable Surrogates</td>
        <td>Model Inversion</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/abs/10.1145/3461702.3462533">On the Privacy Risks of Model Explanations</a></td>
        <td>2021</td>
        <td>AIES</td>
        <td>Feature-based, Shapley, Counterfactual</td>
        <td>Membership Inference</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://ieeexplore.ieee.org/abstract/document/9555622">Adversarial XAI Methods in Cybersecurity</a></td>
        <td>2021</td>
        <td>TIFS</td>
        <td>Counterfactual</td>
        <td>Membership Inference</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2107.08909">MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI</a></td>
        <td>2021</td>
        <td>arXiv</td>
        <td>Gradient-based</td>
        <td>Model Extraction</td>
        <td class='code'>-</td>
        <td><a href="https://github.com/cake-lab/datafree-model-extraction">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1581005&dswid=5229">Robust Counterfactual Explanations for Privacy-Preserving SVM</a></td>
        <td>2021</td>
        <td>ICML-Workshop</td>
        <td>Counterfactual</td>
        <td class='code'>-</td>
        <td>Private SVM</td>
        <td><a href="https://github.com/rami-mochaourab/robust-explanation-SVM">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2106.13203">When Differential Privacy Meets Interpretability: A Case Study</a></td>
        <td>2021</td>
        <td>RCV-CVPR</td>
        <td>Interpretable Models</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://proceedings.mlr.press/v139/gillenwater21a.html">Differentially Private Quantiles</a></td>
        <td>2021</td>
        <td>ICML</td>
        <td>Quantiles</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td><a href="https://github.com/google-research/google-research/tree/master/dp_multiq">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://ieeexplore.ieee.org/document/9647778">FOX: Fooling with Explanations : Privacy Protection with Adversarial Reactions in Social Media</a></td>
        <td>2021</td>
        <td>PST</td>
        <td class='code'>-</td>
        <td>Attribute Inference</td>
        <td>Privacy-Protecting Explanation</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://ieeexplore.ieee.org/abstract/document/9598877/">Privacy-preserving generative adversarial network for case-based explainability in medical image analysis</a></td>
        <td>2021</td>
        <td>IEEE Access</td>
        <td>Example-based</td>
        <td class='code'>-</td>
        <td>Generative Anonymisation</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://ojs.aaai.org/index.php/AAAI/article/view/5827">Interpretable and Differentially Private Predictions</a></td>
        <td>2020</td>
        <td>AAAI</td>
        <td>Locally linear maps</td>
        <td class='code'>-</td>
        <td>Differential Privacy</td>
        <td><a href="https://github.com/frhrdr/dp-llm">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/2009.01884">Model extraction from counterfactual explanations</a></td>
        <td>2020</td>
        <td>arXiv</td>
        <td>Counterfactual</td>
        <td>Model Extraction</td>
        <td class='code'>-</td>
        <td><a href="https://github.com/aivodji/mrce">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/10.1145/3287560.3287562">Model Reconstruction from Model Explanations</a></td>
        <td>2019</td>
        <td>FAT*</td>
        <td>Gradient-based</td>
        <td>Model Reconstruction, Model Extraction</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://arxiv.org/abs/1905.04519">Interpret Federated Learning with Shapley Values</a></td>
        <td>2019</td>
        <td class='code'>-</td>
        <td>Shapley</td>
        <td class='code'>-</td>
        <td>Federated</td>
        <td><a href="https://github.com/crownpku/federated_shap">[Code]</a></td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/10.1145/3308560.3317586">Collaborative Explanation of Deep Models with Limited Interaction for Trade Secret and Privacy Preservation</a></td>
        <td>2019</td>
        <td>WWW</td>
        <td>Feature-based</td>
        <td class='code'>-</td>
        <td>Collaborative rule-based model</td>
        <td class='code'>-</td>
    </tr>
    <tr>
        <td><a href="https://dl.acm.org/doi/abs/10.1145/2810103.2813677">Model inversion attacks that exploit confidence information and basic countermeasures</a></td>
        <td>2015</td>
        <td>CCS</td>
        <td>Confidence scores</td>
        <td>Reconstruction, Model Inversion</td>
        <td class='code'>-</td>
        <td class='code'>-</td>
    </tr>
</table>