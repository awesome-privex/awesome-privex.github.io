<html>

<head>
    <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-PSQTKFXZ');</script>
<!-- End Google Tag Manager -->

    <meta http-equiv="Content-Language" content="en-us">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Awesome Privacy-Preserving XAI</title>
    <link rel="icon" type="image/x-icon" href="/images/favicon.ico">
    <meta http-equiv="Page-Enter" content="revealTrans(Duration=1.0,Transition=3)">
    
    <link href="https://cdn.jsdelivr.net/gh/tofsjonas/sortable/sortable.min.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/gh/tofsjonas/sortable/sortable.min.js"></script>

    <link href="style.css" rel="stylesheet" type="text/css">

    <script>
        function countRows(){
            var noRows = document.getElementById("publicationList").rows.length;
            document.getElementById("totalRows").innerHTML = "Total number of rows: " + (noRows-1);
        }
        
        window.addEventListener('load', function () {
          const el = document.getElementById('year')
          // without id:
          // const el = document.querySelector('.sortable th:first-child')
          // const el = document.querySelector('.sortable th:nth-child(2)')
          // const el = document.querySelectorAll('.sortable')[3].querySelector('th:nth-child(7)')
          // etc.
          if (el) {
            el.click()
          }
        })
    </script>
    
    <style>
        <!--
        li.MsoNormal {
            mso-style-parent: "";
            margin-bottom: .0001pt;
            font-size: 12.0pt;
            font-family: "Times New Roman";
            margin-left: 0in;
            margin-right: 0in;
            margin-top: 0in
        }
        -->
    </style>

</head>

<body BGCOLOR=#FFFFFF background="images/bg.gif" LEFTMARGIN=0 TOPMARGIN=0 MARGINWIDTH=0 MARGINHEIGHT=0 onload="countRows()">

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PSQTKFXZ"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <table width="100%" align="center" border="0" cellpadding="0" cellspacing="0">
        <tr>
            <td align="center">
                <table width="800" bgcolor="#FFFFFF">
                    <tr>
                        <td width="20"></td>
                        <td align="center" valign="top" width="750">
                            <table width="750" border="0" cellpadding="0" cellspacing="0" bgcolor="#FFFFFF">
                                <tr>
                                    <td class="mytitle">A Survey of Privacy-Preserving Model Explanations</td>
                                </tr>
                                <tr>
                                    <td class="subject" style="padding-top:0px; color: #000;">
                                        <b>Awesome Privacy-Preserving Explainable AI</b>
                                    </td>
                                </tr>
                                <tr bgcolor="#FF0000">
                                    <td height="1px" style="padding:2px">
                                    </td>
                                </tr>
                                <tr>
                                    <td class="subTitle" style="padding-top:25px">
                                        I. Introduction
                                    </td>
                                </tr>
                                <tr>
                                    <td class="body">
                                        As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorisation of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have established an online resource repository, which will be continuously updated with new and relevant findings.
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <img class="center" src="images/taxonomy1.png" alt="" border=0  ></img>
                                    </td>
                                </tr>
                                <tr>
                                    <td class="subTitle">
                                        II. List of Approaches (Sortable)
                                    </td>
                                </tr>
                                <tr>
                                    <td class="body" id="totalRows">Total number of rows: XX</td>
                                </tr>

<!-- Start of the table -->

                                <tr>
                                    <td>
                                        <table id="publicationList" class="sortable" style="padding-left:25px">
                                            <thead>
                                                <tr>
                                                    <th class=""><span>Title</span></th>
                                                    <th class="">Venue</th>
                                                    <th class="" id="year">Year</th>
                                                    <th class="">Code</th>
                                                    <th class="">Target Explanations</th>
                                                    <th class="">Attacks</th>
                                                    <th class="">Defenses</th>
                                                </tr>
                                            </thead>
                                            <tbody>


                                                <tr>
                                                    <td><a href="https://www.computer.org/csdl/proceedings-article/sp/2024/313000a120/1Ub23teQ7PG">Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack</a></td>
                                                    <td>2024</td>
                                                    <td>SP</td>
                                                    <td>Feature-based</td>
                                                    <td>Membership Inference</td>
                                                    <td>Differential Privacy, Privacy-Preserving Models, DP-SGD</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://proceedings.mlr.press/v206/pawelczyk23a.html">On the Privacy Risks of Algorithmic Recourse</a></td>
                                                    <td>2023</td>
                                                    <td>AISTATS</td>
                                                    <td>Counterfactual</td>
                                                    <td>Membership Inference</td>
                                                    <td>Differential Privacy</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/full/10.1145/3608482">The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks</a></td>
                                                    <td>2023</td>
                                                    <td>TIST</td>
                                                    <td>Counterfactual</td>
                                                    <td>Linkage</td>
                                                    <td>Anonymisaion</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/abs/10.1145/3580305.3599343">Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations</a></td>
                                                    <td>2023</td>
                                                    <td>KDD</td>
                                                    <td>Counterfactual</td>
                                                    <td class='code'>-</td>
                                                    <td>Perturbation</td>
                                                    <td><a href="https://github.com/isVy08/L2C/">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://petsymposium.org/popets/2023/popets-2023-0041.pdf">Private Graph Extraction via Feature Explanations</a></td>
                                                    <td>2023</td>
                                                    <td>PETS</td>
                                                    <td>Feature-based</td>
                                                    <td>Graph Extraction</td>
                                                    <td>Perturbation</td>
                                                    <td><a href="https://github.com/iyempissy/graph-stealing-attacks-with-explanation">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2311.14137">Privacy-Preserving Algorithmic Recourse</a></td>
                                                    <td>2023</td>
                                                    <td>ICAIF</td>
                                                    <td>Counterfactual</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2308.04341">Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage</a></td>
                                                    <td>2023</td>
                                                    <td>ICML-Workshop</td>
                                                    <td>Counterfactual</td>
                                                    <td>Membership Inference</td>
                                                    <td>Differential Privacy</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2308.15099">Probabilistic Dataset Reconstruction from Interpretable Models</a></td>
                                                    <td>2023</td>
                                                    <td>arXiv</td>
                                                    <td>Interpretable Surrogates</td>
                                                    <td>Data Reconstruction</td>
                                                    <td class='code'>-</td>
                                                    <td><a href="https://github.com/ferryjul/ProbabilisticDatasetsReconstruction">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1495">DeepFixCX: Explainable privacy-preserving image compression for medical image analysis</a></td>
                                                    <td>2023</td>
                                                    <td>WIREs-DMKD</td>
                                                    <td>Case-based</td>
                                                    <td>Identity recognition</td>
                                                    <td>Anonymisation</td>
                                                    <td><a href="https://github.com/adgaudio/DeepFixCX">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://eprint.iacr.org/2023/1859">XorSHAP: Privacy-Preserving Explainable AI for Decision Tree Models</a></td>
                                                    <td>2023</td>
                                                    <td>Preprint</td>
                                                    <td>Shapley</td>
                                                    <td class='code'>-</td>
                                                    <td>Multi-party Computation</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td class='code'>-</td>
                                                    <td>2023</td>
                                                    <td>Github</td>
                                                    <td>ALE plot</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td><a href="https://github.com/lange-martin/dp-global-xai">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557362">Inferring Sensitive Attributes from Model Explanations</a></td>
                                                    <td>2022</td>
                                                    <td>CIKM</td>
                                                    <td>Gradient-based, Perturbation-based</td>
                                                    <td>Attribute Inference</td>
                                                    <td class='code'>-</td>
                                                    <td><a href="https://github.com/vasishtduddu/AttInfExplanations">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/abs/10.1145/3531146.3533235">Model explanations with differential privacy</a></td>
                                                    <td>2022</td>
                                                    <td>FAccT</td>
                                                    <td>Feature-based</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/10.1145/3531146.3533188">DualCF: Efficient Model Extraction Attack from Counterfactual Explanations</a></td>
                                                    <td>2022</td>
                                                    <td>FAccT</td>
                                                    <td>Counterfactual</td>
                                                    <td>Model Extraction</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/abs/10.1145/3548606.3560573">Feature Inference Attack on Shapley Values</a></td>
                                                    <td>2022</td>
                                                    <td>CCS</td>
                                                    <td>Shapley</td>
                                                    <td>Attribute/Feature Inference</td>
                                                    <td>Low-dimensional</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://ieeexplore.ieee.org/abstract/document/10063510/">Evaluating the privacy exposure of interpretable global explainers</a></td>
                                                    <td>2022</td>
                                                    <td>CogMI</td>
                                                    <td>Interpretable Surrogates</td>
                                                    <td>Membership Inference</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://ieeexplore.ieee.org/document/9729808/">Privacy-Preserving Case-Based Explanations: Enabling Visual Interpretability by Protecting Privacy</a></td>
                                                    <td>2022</td>
                                                    <td>IEEE Access</td>
                                                    <td>Example-based</td>
                                                    <td class='code'>-</td>
                                                    <td>Anonymisation</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2206.14004">On the amplification of security and privacy risks by post-hoc explanations in machine learning models</a></td>
                                                    <td>2022</td>
                                                    <td>arXiv</td>
                                                    <td>Feature-based</td>
                                                    <td>Membership Inference</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2208.02878">Differentially Private Counterfactuals via Functional Mechanism</a></td>
                                                    <td>2022</td>
                                                    <td>arXiv</td>
                                                    <td>Counterfactual</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2206.00511">Differentially Private Shapley Values for Data Evaluation</a></td>
                                                    <td>2022</td>
                                                    <td>arXiv</td>
                                                    <td>Shapley</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td><a href="https://github.com/amiratag/DataShapley">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Exploiting_Explanations_for_Model_Inversion_Attacks_ICCV_2021_paper.html">Exploiting Explanations for Model Inversion Attacks</a></td>
                                                    <td>2021</td>
                                                    <td>ICCV</td>
                                                    <td>Gradient-based, Interpretable Surrogates</td>
                                                    <td>Model Inversion</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/abs/10.1145/3461702.3462533">On the Privacy Risks of Model Explanations</a></td>
                                                    <td>2021</td>
                                                    <td>AIES</td>
                                                    <td>Feature-based, Shapley, Counterfactual</td>
                                                    <td>Membership Inference</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://ieeexplore.ieee.org/abstract/document/9555622">Adversarial XAI Methods in Cybersecurity</a></td>
                                                    <td>2021</td>
                                                    <td>TIFS</td>
                                                    <td>Counterfactual</td>
                                                    <td>Membership Inference</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2107.08909">MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI</a></td>
                                                    <td>2021</td>
                                                    <td>arXiv</td>
                                                    <td>Gradient-based</td>
                                                    <td>Model Extraction</td>
                                                    <td class='code'>-</td>
                                                    <td><a href="https://github.com/cake-lab/datafree-model-extraction">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1581005&dswid=5229">Robust Counterfactual Explanations for Privacy-Preserving SVM</a></td>
                                                    <td>2021</td>
                                                    <td>ICML-Workshop</td>
                                                    <td>Counterfactual</td>
                                                    <td class='code'>-</td>
                                                    <td>Private SVM</td>
                                                    <td><a href="https://github.com/rami-mochaourab/robust-explanation-SVM">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2106.13203">When Differential Privacy Meets Interpretability: A Case Study</a></td>
                                                    <td>2021</td>
                                                    <td>RCV-CVPR</td>
                                                    <td>Interpretable Models</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://proceedings.mlr.press/v139/gillenwater21a.html">Differentially Private Quantiles</a></td>
                                                    <td>2021</td>
                                                    <td>ICML</td>
                                                    <td>Quantiles</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td><a href="https://github.com/google-research/google-research/tree/master/dp_multiq">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://ieeexplore.ieee.org/document/9647778">FOX: Fooling with Explanations : Privacy Protection with Adversarial Reactions in Social Media</a></td>
                                                    <td>2021</td>
                                                    <td>PST</td>
                                                    <td class='code'>-</td>
                                                    <td>Attribute Inference</td>
                                                    <td>Privacy-Protecting Explanation</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://ieeexplore.ieee.org/abstract/document/9598877/">Privacy-preserving generative adversarial network for case-based explainability in medical image analysis</a></td>
                                                    <td>2021</td>
                                                    <td>IEEE Access</td>
                                                    <td>Example-based</td>
                                                    <td class='code'>-</td>
                                                    <td>Generative Anonymisation</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://ojs.aaai.org/index.php/AAAI/article/view/5827">Interpretable and Differentially Private Predictions</a></td>
                                                    <td>2020</td>
                                                    <td>AAAI</td>
                                                    <td>Locally linear maps</td>
                                                    <td class='code'>-</td>
                                                    <td>Differential Privacy</td>
                                                    <td><a href="https://github.com/frhrdr/dp-llm">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/2009.01884">Model extraction from counterfactual explanations</a></td>
                                                    <td>2020</td>
                                                    <td>arXiv</td>
                                                    <td>Counterfactual</td>
                                                    <td>Model Extraction</td>
                                                    <td class='code'>-</td>
                                                    <td><a href="https://github.com/aivodji/mrce">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/10.1145/3287560.3287562">Model Reconstruction from Model Explanations</a></td>
                                                    <td>2019</td>
                                                    <td>FAT*</td>
                                                    <td>Gradient-based</td>
                                                    <td>Model Reconstruction, Model Extraction</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://arxiv.org/abs/1905.04519">Interpret Federated Learning with Shapley Values</a></td>
                                                    <td>2019</td>
                                                    <td class='code'>-</td>
                                                    <td>Shapley</td>
                                                    <td class='code'>-</td>
                                                    <td>Federated</td>
                                                    <td><a href="https://github.com/crownpku/federated_shap">[Code]</a></td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/10.1145/3308560.3317586">Collaborative Explanation of Deep Models with Limited Interaction for Trade Secret and Privacy Preservation</a></td>
                                                    <td>2019</td>
                                                    <td>WWW</td>
                                                    <td>Feature-based</td>
                                                    <td class='code'>-</td>
                                                    <td>Collaborative rule-based model</td>
                                                    <td class='code'>-</td>
                                                </tr>
                                                <tr>
                                                    <td><a href="https://dl.acm.org/doi/abs/10.1145/2810103.2813677">Model inversion attacks that exploit confidence information and basic countermeasures</a></td>
                                                    <td>2015</td>
                                                    <td>CCS</td>
                                                    <td>Confidence scores</td>
                                                    <td>Reconstruction, Model Inversion</td>
                                                    <td class='code'>-</td>
                                                    <td class='code'>-</td>
                                                </tr>


                                            </tbody>
                                        </table>
                                    </td>
                                </tr>


<!-- End of the table -->

                                <tr>
                                    <td class="subTitle">
                                        III. Citations
                                    </td>
                                </tr>
                                <tr>
                                    <td class="item" style="padding-top: 10px;">
                                        <span><b>Source:</b></span> <a target="_blank"
                                            href="https://github.com/tamlhp/awesome-privex">https://github.com/tamlhp/awesome-privex</a>
                                    </td>
                                </tr>
                                <tr>
                                    <td class="item" style="padding-top: 10px;">
                                        <span><b>Paper:&nbsp;&nbsp;</b></span> <a target="_blank"
                                            href="https://arxiv.org/abs/2404.00673">https://arxiv.org/abs/2404.00673</a>
                                    </td>
                                </tr>
                            </table>
                        </td>
                        <td width="25"> </td>
                    </tr>
                    <tr height="20px">
                        <td>
                        </td>
                    </tr>
                    <tr bgcolor="#CCCCCC">
                        <td height="1px" colspan="3" style="padding:0px;">
                        </td>
                    </tr>
                    <tr>
                        <td align="center" height="1px" width="757" colspan="3" bgcolor="#FFFFFF"
                            style="padding:0px; margin-top: 0px;">
                            <font color="#e2ebfe" face="Tahoma" style="FONT-SIZE: 8pt">
                                <b>
                                    <font color="#666666">© 2024
                                        Privacy-Preserving Explainable AI </font>
                                </b></font>&nbsp;
                        </td>
                    </tr>
                    <tr bgcolor="#CCCCCC">
                        <td height="10px" colspan="3" style="padding:0px;">
                        </td>
                    </tr>
                </table>
            </td>
        </tr>
    </table>
</body>

</html>
